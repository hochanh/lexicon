_Nguồn:_ [Blog khoa học máy tính](http://www.procul.org/blog/2010/11/09/lexicon-xac-su%E1%BA%A5t-th%E1%BB%91ng-ke-va-h%E1%BB%8Dc-may/)

# **1. Lý thuyết xác suất:**

## **1.1 Căn bản**: Lý thuyết xác suất cho chúng ta một ngôn ngữ để mô tả sự **_ngẫu nhiên_** (randomness). Đối tượng cơ bản nhất của LTXS là các _biến ngẫu nhiên_ (random variables).&nbsp; Để định nghĩa một biến ngẫu nhiên thì cần một _**hàm phân bố** _(distribution function), qua đó có thể định nghĩa được các khái niệm như _trung bình_ (mean) và _**phương sai**_ (variance). Standard deviation gọi là **_độ lệch chuẩn_**. Mean và variance là các _**phiếm hàm**_ (functionals), được áp dụng cho một hàm phân bố hoặc một biến ngẫu nhiên. Hàm phân bố nếu liên tực tuyệt đối với một độ đo chuẩn (?) như Lebesgue thì có thể được biểu diễn bởi **_hàm mật độ_** (density), theo định lý Radon-Nikodym.

Cơ sở toán học của lý thuyết xác suất là _thuyết độ đo_ (measure theory), nhưng việc chính của các xác suất gia (?) (probablist) là xây dựng phát triển cáng nhiều loại đo đo xác suất càng tốt. Nói chuyện với một chuyên gia độ đo không thể không định nghĩa một _đại số sigma_ (sigma-algebra). Nói chuyện với một chuyên gia xác suất thì rất nhiều khi khái niệm này ẩn rất kỹ. Công cụ chính của các XSG chính là khái niệm _**độc lập** _(independence), và mạnh mẽ hơn là _**độc lập có điều kiện**_ (conditional independence). Cho nên dân toán thường trêu LTXS chẳng qua là thuyết độ đo + độc lập. Vậy sự khác biệt giữa một độ đo xác suất và những biến ngẫu nhiên là gì? Theo David Aldous thì đó là sự khác biệt giữa recipe để làm bánh và những cái bánh. Hiểu được sự khác biệt này thì mới làm được bước nhảy từ lý thuyết độ đo khô khan sang lý thuyết xác suất tươi mát hơn.

## **1.2 Độc lập và hội tụ:** Khái niệm độc lập cho ta một loạt các định luật cơ bản của LTXS. Tất cả đều xoay quanh _hiện tượng **tập trung của độ đo**_ (concentration of measure). Bắt đầu là **_luật các số lớn_** (có phiên bản_ luật mạnh_ (strong law) và_ luật yếu_). Luật **_giới hạn trung tâm_ **(Central limit theorem) nhắc rằng sample mean (**_mẫu trung bình_**)&nbsp; có quy luật **_bình thường_** (normal/Gaussian) khi số mẫu tiến đến vô hạn. Các định luật này đều có sử dụng các khái niệm _hội tụ_ (convergence) trong giải tích. Hội tụ **_gần chắc_** (almost sure), _**hội tụ về phân bố hoặc về luật** _(convergence in distribution/ in law).&nbsp; Ngoài luật số lớn còn có **_luật các số nhỏ_ **(hay luật các hiện tượng hiếm có — law of rare events), cho ta biết khi nào thì mẫu trung bình có quy luật Poisson. Không phải ngẫu nhiên, Gaussian và Poisson là hai hàm phân bố căn bản nhất — là những viên gạch cho toàn bộ lâu đài XS.

Khái niệm độc lập và độc lập có điều kiện là những chất keo để gắn kết các biến xác suất với nhau, qua đó cho ta các hàm xác suất cho các vật thể toán học có cấu trúc phức tạp hơn. Một dạng độc lập có điều kiện hay dùng là tính chất Markov. Ngoài chất keo độc lập, còn có một chất keo nữa rất hữu dụng, đó là **_tính hoán chuyển được_** (exchangeability).&nbsp; Nếu tính độc lập là nền tảng cho các phương pháp **_suy diễn tần số_** (frequentist) , thì tính hoán chuyển được lại là cơ sở nền tảng cho các phương pháp** suy diễn Bayesian**. Tính hoán chuyển được đang được mở rộng ra thành _**hoán chuyển từng phần**_ (partial exchangeability), một khái niệm quan trọng để phái triển các độ đo cho các _**vật thể tổ hợp **_(combinatorial object) rời rạc và phức tạp.

## **1.3 Quá trình ngẫu nhiên:** LTXS phát triển rất nhiều hàm phân bố không chỉ cho các biến xác suất scalar (?) đơn giản, mà người ta còn sáng tạo ra các hàm phân bố cho các cấu trúc toán học phức tạp, nhiều chiều hơn. Chúng ta bắt đầu nói chuyện đến hàm phân bố cho những _tập các hàm số đo được_ (measurable functions), và hàm phân bố cho các _**độ đo ngẫu nhiên**_ (random measures). Hàm phân bố cho các vật thể vô hạn chiều này gọi chung là các **_quá trình ngẫu nhiên_** (stochastic processes). Cách thức khẳng định sự tồn tại là qua định lý của bác Kolmogorov, cho phép ta hiểu về các hàm phân bố cho không gian vô hạn chiều từ các điều kiện **_nhất quán_** (consistency) của độ đo cho các _cylinder sets_. Đây là cách để chúng ta xây dựng được các hàm phân bố cho _quá trình Gauss_ (Gaussian processes), _quá trình Dirichlet_ (Dirichlet process), v.v.

Một cách hữu hiệu để xây dựng một quá trình stochastic là quay lại với khái niệm độc lập, và đẩy khái niệm này đến giới hạn. Công cụ ở đây là nhìn vào _phép biến đổi Fourier_ (Fourier transform) của các hàm phân bố.&nbsp; Theo ngôn ngữ XS thì khái niệm này gọi là **_hàm tính cách_** (characteristic function). Để đẩy khái niệm độc lập tới giới hạn thì ta cần khái niệm các hàm phân bố **_khả phân vô hạn_** (infinitely divisible). Khái niệm tiếp theo là các hàm **_phân bố ổn định_ **(stable distribution). Gauss và Poisson chính là hai hàm phân bố ổn định — không phải là “ngẫu nhiên” nếu chúng ta quay về các luật số lớn và số nhỏ nhắc ở trên. Max-stable là một họ**_ phân bố cực đại ổn định_**.

Các quá trình ngẫu nhiên có tính chất **_gia tăng độc lập_** (independent increment) gọi là quá trình Lévy. Tổng quát hơn một chút là các **_độ đo hoàn toàn độc lập_** (completely random measures). Định lý biểu diễn Lévy-Khintchine cho chúng ta biết rõ hàm tính cách của các quá trính stochastic này là gì, thông qua _độ đo Lévy _(Levy measure). Chọn độ đo Lévy thích hợp (beta, gamma, v.v.) thì ta sẽ có một quá trính stochastic tương ứng. Định lý này cho ta thấy tại sao Gauss và Poisson lại trở thành các viên gạch chỉ của các lâu đài xác suất đồ sộ:&nbsp; Theo định lý Lévy-Itó, dựa trên biểu diễn L-K thì tất cả các quá trính Lévy đều có thể được decompose _(<span style="text-decoration: line-through;">phân rã</span>) (phân tách) _thành tổng của ba quá trình stochastic độc lập, một là quá trình Wiener (một dạng quá trình Gauss), với quá trình **_phức hợp_** (compound) Poisson, và một là quá trình martingale.

Rất khó tưởng tượng các tập con đo được của sigma đại số đối với các quá trính ngẫu nhiên. Thay vì hình dung sigma đại số (recipe làm bánh) thì ta có thể mô tả những cái bánh. Nếu quá trình được liệt kê bởi tham số thởi gian, thì một cái bánh ở đây có thể hiểu là một _lối mẫu_ (sample path). Với một số quá trình ngẫu nhiên thì có thể mô tả cách tạo mẫu từ một quá trình ngẫu nhiên bằng phương pháp _nhặt mẫu từ giỏ Pólya_ (Pólya’s urn).&nbsp; Rất nhiều quá trình ngẫu nhiên có thể được mô tả bằng **_biểu diễn bẻ gậy_** (stick-breaking representation). Theo biểu diễn này thì cần các _nguyên tử_ (atom) và các _mẩu gậy_ (stick-breaking weight). Cách thức bẻ gậy và nhặt nguyên tử đều dựa theo cơ sở của độc lập có điều kiện, một chất keo kỳ diệu cho phép ta mô tả các cấu trúc phức tạp bằng các nguyên liệu giản đơn hơn.

Được quan tâm hàng đầu là biểu hiện của giá trị _kỳ vọng_ (expectation) của một vật thể xác suất. Liên quan là khái niệm kỳ vọng điều kiện (conditional expectation), bản thân nó cũng là một biến ngẫu nhiên. Một công cụ quan trọng là khái niệm martingale. Martingale có thể được mô tả dưới dạng một quá trình NN, tạm gọi là _**quá trình đánh bạc**_(?). Cần khái niệm filtration (_**hệ thống lọc**_). Ngoải ra ta còn có submartingale, supermartingale và semimartingale (?). Nhờ các công cụ này mà ta có thể tìm hiểu các khái niệm xác suất hữu ích như** _thời điểm dừng_** (stopping time), **_thời điểm chạm_** (hitting time), **_thời gian/thởi điểm vượt biên_** (boundary crossing time).

Một họ quá trình NN rất thông dụng là _quá trình Markov_ (Markov process). Định nghĩa trên cơ sở **_hạch xác suất chuyển dịch_** (transition probability kernel), và khái niệm hệ thống lọc. Cần khái niệm subordinator (?), một dạng quá trình Lévy quan trọng. Local time được dịch là **_thời gian địa phương_**. Quá trình Markov cho thời gian rời rạc còn gọi là _**chuỗi Markov** (hoặc** xích Markov**)._ Liên qua đến chuỗi Markov là lý thuyết ergodic (?). Irreducibility dịch là **_bất khả quy_**.&nbsp; Một vấn đề được quan tâm là _thời gian **hòa tan**_ (mixing time) của chuỗi Markov.&nbsp; Điều kiện cần cho chuỗi Markov được hòa tan về một trạng thái _phân bố bất dịch (phân bố dừng)_ (stationary distribution)&nbsp; là ergodicity, thỏa mãn phương trính** c_ân bằng chi tiết_** (detailed balance). Chuỗi Markov định nghĩa cho không gian rởi rạc (_**dàn**_ lattice chẳng hạn) thì sẽ trở thành quá trình** _đi bộ ngẫu nhiên_** (random walk).&nbsp; Gọi lattice là dàn thiên lý rất hay, thế phải phân biệt với dàn nho thế nào đây. Khái niệm coupling trong chuỗi Markov dịch là sự **cặp đôi**. Coupling from the past? Quá đơn giản, **cặp nhau từ quá khứ**! Time-homogeneous Markov process gọi là **_quá trình Markov đồng biến_**.

Nói đến quá trình ta thường nghĩ đến thời gian — cụ thể là các quá trình NN thường được hiểu là tập hợp các hàm phân bố nhất quán (consistent) được liệt kê bởi một tham số chỉ thời gian. Không nhất thiết phải như vậy. Mở rộng khái niệm tham số thời gian ra một không gian bất kỳ (ví dụ không gian Euclidean, dàn, hoặc không gian phi-Euclidean), thì ta có quá trình NN tổng quát hơn. Markov random fields sẽ được gọi là **_trường ngẫu nhiên Markov_**. Gaussian random field là **_trường ngẫu nhiên Gauss_**. Poisson point process gọi là **_quá trình điểm Poisson_** (lại quá trình, nhưng kỳ thực phải gọi là trường Poisson mời phải!) . Spatial process là quá trình không gian (?). Spatiotemporal process gọi là quá trình không-thời gian. Khái niệm phase transition rất hay trong trường ngẫu nhiên Markov của một dàn vô hạn, ta sẽ dịch là _**hiện tượng chuyển pha**_.

Một dạng quá trình NN khá hay ho gọi là empirical process (**_quá trình thực nghiệm_**). Thường được nghiên cứu để tìm hiểu về tính hiệu quả của các phương pháp suy diễn thống kê, thay vì dùng để mô tả một quá trình ngẫu nhiên trong tự nhiên. Sẽ nói&nbsp; ở mục sau.

Các khái niệm quan trọng khác: percolation, excursion, optional stopping

# **2. Mô hình thống kê**

## **2.1 Căn bản. **_**Mô hình thống kê**_ (statistical model) cũng là mô hình xác suất, sử dụng từ các nguyên liệu được phát triến cho các hàm phân bố vá các quá trình NN trong LTXS. Cái khác ở đây là trong mô hình thống kê có một số biến ngẫu nhiên được gán nhãn là _**dữ liệu**_ (data), những biến số ngẫu nhiên mà chúng ta có thể quan sát, hoặc thu thập được giá trị bằng thực nghiệm và các thiết bị công nghệ. Cho nên trọng tâm của việc xây dựng mô hình thống kê là làm sao _**ước lượng**_ (estimate) /_**học**_ (learn) được mô hình này từ dữ liệu, làm sao có thể đánh giá được tính _**hiệu quả**_ (efficiency) hoặc tính _**phổ quát**_ (generalization) của mô hình, làm sao có thể _**chọn ra được mô hình**_ hữu ích (model selection/model choice).

## **2.2 Tham số.** Để kiểm soát được độ phức tạp của mô hình thì công cụ chính ở đây là phải **tham số** hóa (parameterization) mô hình. Các **_tham số_** (parameter) là phần còn lại của mô hình xác suất mà chúng ta phải ước lượng, học. Đến đây có một vấn đề nho nhỏ, các tham số là một giá trị không biết nhưng không ngẫu nhiên, hay bản thân chúng là ngẫu nhiên. Có hai cách tiếp cận vấn đề này, **_trường phái tần suất_** giả dụ cách đẩu, còn _**trường phái Bayes**_ thì giả dụ cách sau. Nếu các tham số là có số chiều hữu hạn, ta có một **_mô hình tham số_** (parametric model), nếu số chiều là vô hạn thì ta có _**mô hình phi tham số**_ (nonparametric model). Như vậy, gọi là phi tham số không có nghĩa là không có tham số. Nếu tham số là ngẫu nhiên mà lại vô hạn chiều thì người ta gọi mô hình là **_mô hình phi tham số Bayes_** (Bayesian nonparametric model). Điều này không có nghĩa làm việc với các mô hình dạng này là theo trường phái Bayes, mặc dù trên thực tế thì phần lớn những người phát triến mô hình phức tạp nói chung và mô hình phi tham số Bayes nói riêng lại có nhãn quan Bayes. Song không nhất thiết phải vậy.

## **2.3 Đầy đủ và thông tin**. Một công cụ quan trọng trong việc tham số hóa là khái niệm_** thống kê đầy đủ**_ (sufficient statistics). Để hiểu khái niệm này phải hiểu khái niệm _**thống kê**_ là gì. Một thống kê là một hàm số được áp dụng vào các dữ liệu (cộng trừ nhân chia kiểu gì cũng được). Liên hệ với khmt thì thống kê chính là _**đầu ra**_ (output) của một _**giải thuật**_ sử dụng dữ liệu như là _**đầu vào**_.&nbsp; Còn thống kê đầy đủ đối với một mô hình là những thống kê chứa đựng mọi thông tin có thể có được từ dữ liệu về các tham số của mô hình. Nghĩa là nếu vứt hết dữ liệu đi, chỉ cần giữa lại các thống kê đầy đủ, vẫn không bị mất thông tin gì về mô hình. Đây có lẽ là một trong những khái niệm đẹp đẽ nhất của toàn bộ thống kê học. Sau khi quyết định được thống kê đầy đủ rồi người ta có thể biết được rằng dữ liệu phải là mẫu của một hàm phân bố có một cách tham số hóa nhất định, qua một định lý _**biểu diễn phân tích Fisher-Neyman**_ (Fisher-Neyman factorization theorem). Nhắc thêm khái niệm thống kê đầy đủ là một khái niệm có tính lý thuyết **thông tin** (information-theoretic), có thể phát biểu bằng tính _độc lập có điều kiện_ và các khái niệm entropy.

Một loạt các mô hình đẹp có thể được động viên từ khái niệm cần và đủ kiểu này. Mô hình _**họ mũ**_ (exponential family) là mô hình tạo ra dữ liệu ngẫu nhiên nhất có thể được, nếu các thống kê đầy đủ đã được cho. _**Mô hình xác suất đồ thị **_(probabilistic graphical model) là mô hình duy nhất thỏa mãn các ràng buộc về độc lập có điều kiện cho các biến ngẫu nhiên, theo định lý Hammersley-Clifford. Nếu các biến ngẫu nhiên được giả dụ là hoán chuyển được, thì chúng bắt buộc phải được mô tả bởi một _**mô hình trộn/ mô hình hỗn hợp **_(mixture model), theo định lý nổi tiếng của de Finetti. Nếu các biến ngẫu nhiên có hàm phân bố không thay đổi kể cả khi bị _**biến đổi trực chuẩn**_ (orthornomal transformation) thì chúng bắt buộc phải được mô tả bởi một elliptically contoured distribution (_**phân bố có đường cong ê líp**_), kiểu như Gauss đa biến vậy.

## **2.4 ****Nhãn quan Bayes và tần suất**. Các mô hình thống kê cho ta keo dính để gắn kết các dữ liệu với nhau, và là đối tượng trung tâm của ngành thống kê. Nhưng trong lịch sử và đến tận bây giờ, các mô hình vẫn được trường phái Bayes chào đón nồng nhiệt hơn là trường phái tần suất, bởi vì sự lệ thuộc vào một mô hình thống kê làm cho người ta liên tưởng đến sự lệ thuộc vào _**tiên nghiệm**_ (prior knowledge) quá nhiều, và do đó thiếu đi sự “khách quan”. Đặc biệt trong trường phái Bayes có một nhánh gọi là **_Bayes chủ quan_** (subjective Bayes) và _**Bayes khách quan**_. Những người theo Bayes chủ quan cho rằng, nếu ta có những _**niềm tin chủ quan **_(subjective belief) nhất định về dữ liệu, thì ta sẽ sử dụng một mô hình xác suất tương ứng, do các định lý kiểu như của de Finetti và Hammersley-Clifford kể trên. Một mảng không nhỏ của ngành thống kê học, thuộc trường phái tấn suất, tập trung vào các phương pháp _**mô hình tự do**_ (distribution free), qua đó không sử dụng một mô hình xác suất cụ thể nào, mặc dù họ có giả sử là tộn tại một hàm phân bố để tạo ra các mẫu dữ liệu một cách độc lập.&nbsp; Chú ý rằng điều này không có nghĩa là các nhà tần suất là khách quan hơn các nhà Bayes chủ quan, vì sự giả dụ tính độc lập nói chung là mạnh hơn sự giả dụ tính độc lập điều kiện, hay tính hoán chuyển được. Cả hai cách nhìn Bayes và tần suất đều hữu ích trong các ngữ cảnh khác nhau, và về nhiều mặt không có phe hoàn toàn đúng. Cả hai cách nhìn này đều chứa chất mâu thuẫn trong mình, có sự đối chọi nhau, nhưng cũng có sự tương hỗ nhau giống như bức tranh âm-dương trong Kinh Dịch vậy. Ta sẽ tiếp tục soi lại quan hệ này mỗi khi có dịp.

## **2.5 Phân lớp các mô hình cụ thể và cách tham số hóa**.&nbsp; Các mô hình thống kê giống như các sinh vật trong thế giới tự nhiên, rất đa dạng và có thể được phân lớp, và có thể quan sát sự phức tạp tăng dần với quá trình phát triển của ngành. Trong ngành học máy thì một số người còn gọi một mô hình là một cái máy (machine), nghe công nghệ, hiện đại và mới mẻ hơn. Để mô tả một mô hình thì cần phải nói cách tham số hóa của chúng thế nào, nên cần rất nhiều khái niệm và lexicon. Tham số hóa thế nào chính là vấn đề cơm và nước mắm của người học thống kê.

Với rất nhiều biến ngẫu nhiên, cần phải định ra joint distribution (_**phân bố liên hợp**_). Marginal distribution gọi là ? Conditional distribution gọi là phân bố điều kiện. Covariates gọi là _**đồng biến**_. Trong công nghệ thường là đầu vào. Features thực ra cũng là đồng biến, nhưng xuất xứ từ học máy, và sẽ gọi là _**đặc trưng**_.

Trong họ mũ, có hai cách tham số hóa. Natural parameterization gọi là cách**_ tham số hóa tự nhiên_**. Canonical parameterization gọi là **_tham số hóa chính tắc_**? Còn gọi là **_tham số hóa trung bình_** (mean parameterization). Hai hệ tham số kể trên có liên hệ mất thiết với nhau qua quan hệ**_ đối ngẫu liên hợp_** (conjugate duality), một khái niệm của giải tích lồi (convex analysis). Trong _**hình học thông tin**_ (information geometry) thì hai hệ tham số này có thể hiểu qua khái niệm e-flat manifold và m-flat manifold (?). Normalizing constant gọi là _**hắng số chuẩn hóa**_. trong vật lý thống kê thì khái niệm này còn gọi là partition function — **_hàm ngăn phần_**. Các mô hình thông dụng trong vật lý lý thuyết như mô hình Ising, spin glass (?), đều là trường hợp đặc biệt của họ mũ. Rất nhiều hàm phân bố là trường hợp đặc biệt của họ mũ. Đặc biệt quan trọng là multivariate Gaussian dịch là **_Gauss đa biến_**. Mean vector và covariance matrix gọi là **_vector trung bình_** và ma trận _**hiệp phương sai**_.

Mô hình họ mũ lại là trường hợp đặc biệt của họ **_mô hình xác suất đồ thị _**(graphical model). Phân biệt graphical và graph và graphics thể nào đây? Để định nghĩa mô hình này cần potential function (**_hàm tiềm năng_**), được định nghĩa trên clique (?) của các biến ngẫu nhiên. Có hai loại mô hình XSDT. Một là **_mô hình đồ thị vô hướng_** (undirected graphical model), cũng đồng nghĩa với trường ngẫu nhiên Markov (Markov random fields). Một là **_mô hình đồ thị có hướng_** (directed graphical model), còn gọi là _**mạng Bayes**_ (Bayesian network) của Pearl. Trong mạng Bayes có khái niệm **_nốt cha_** và **_nốt con_**. Khái niệm moralization gọi là _**lấy nhau**_. Một số trường hợp thông dụng của mạng Bayes có thể kể đến mô hình **_cây xác suất ĐT_** (tree-structured graphical model), mô **_hình đa&nbsp; cây_** (polytree) nhưng có lẽ gọi là **_cây đa_** cũng thích hợp, mô hình **_Markov ẩn_** (hidden Markov), mô hình _**lọc Kalman**_ (Kalman filter), **_mài trơn Kalman_** (Kalman smoothing) … Latent/hidden variables gọi là các _**biến ẩn**_. Naive Bayes tạm gọi là _**Bayes thơ ngây**_, hoặc Bây ngô. Mạng Bayes cho các dạng dữ liệu tuần tự (sequential data) còn gọi là dynamic Bayes net (?).

Một số mô hình tham số khác phải kể đến: Mô hình _**hổi quy tuyến tính**_,_** mạng nơ ron**_ (neural network), mô hình **_cây quyết định_** (decision tree), mô hình_** hợp xướng**_ (ensemble), mô hình _**hổi quy logit**_ (logistic regression), mô hình **_tuyến tính tổng quát_** (generalized linear model), mô hình**_ mạng tin, mạng tin sâu_** (deep belief net). v.v. Những mô hình kiểu này thường áp dụng vào các vấn đề suy diễn cụ thể hơn, đặc biệt trong bài toán phân lớp (classification) và hồi quy (regression). Có một số cách phân loại nữa: Trong học máy thì các mô hình dự trên hàm phân bố xác suất liên hợp thường gọi là _**mô hình sinh mẫu**_ (generative model), nhưng cũng có một số mô hình áp dụng cho các vẫn đề liên quan đến xác suất điều kiện thì gọi là _**mô hình phân biệt**_ (discriminative model). Cái sau hay được dùng cho các kiểu suy diễn đặc biệt hơn như bài toán phân lớp, bài toán phân hạng, v.v.

Một mô hình bao gồm cả tham số có số chiều hữu hạn và tham số có số chiều vô hạn thường gọi là _**mô hình bán tham số**_ (semiparametric model).&nbsp; Một ví dụ tiêu biểu là **_mô hình hồi quy Cox_** (Cox regression model) trong bài toán _**phân tích sống sót**_ và **_phân tích sự kiện lịch sử_** (survival analysis/ event history analysis). Time to event data dịch là dữ liệu sự kiện. Trong mô hình này, thành phần tham số hữu hạn gắn liền với những đồng biến (covariates) quan tâm,&nbsp; thành phần tham số vô hạn là **_c__ường độ tử vong/lỗi cơ bản_** (baseline hazard intensity). Đôi khi họ các mô hình bán tham số được gộp chung vào họ các mô hình phi tham số.

Họ các mô hình phi tham số Bayes được lấy từ các quá trình ngẫu nhiên kể trên. Infinite mixture model gọi là **_mô hình trộn/ hỗn hợp vô hạn_**. Có các quá trình đậm chất ẩm thực: Quá trình **_nhà hàng Tàu_** (Chinese restaurant process), _q_**_uá trình búp phê Ấn độ _**(Indian buffet process). Quá trình coelescence gọi là gì? Với dân tần suất thì nhiều khi các mô hình phi tham số chỉ là tập các hàm quen thuộc trong giải tích hàm. Ví dụ _**lớp Sobolev**_ (Sobolev class), _**lớp Besov**_, **_không gian Hilbert_** _**nhân tự sinh**_ (reproducing kernel Hilbert space), lớp smoothing splines (?), v.v.&nbsp; Dân Bayes sẽ luôn luôn nói về các hàm phân bố (độ đo) cho các hàm số kiểu này.

Dân Bayes còn có một việc là phải tham số hóa các tham số. Theo cách nhìn Bayes, các tham số cũng ngẫu nhiên, phải được giả dụ bởi một hàm phân bố khác. Các tham số của hàm này sẽ là hyperparameter (**_tham số tầng trên/ tham số thượng tầng?_**). Nếu là người theo Bayes cuồng tín, thì các tham số thượng tầng này cũng phải ngẫu nhiên… và phải tiếp tục quá trình tham số này đến tận Big Bang. Điều này dẫn đến một họ **_mô hình đa tầng_** (hierarchical model/ multi-level model), rất mạnh và rất giàu. Tuy có thể coi là một trường hợp của mô hình XSDT, nhưng trọng tâm và nguổn gốc rất khác, nên ta không nên gộp làm một. (Chú ý là ta không thể đi đến tận Big Bang, nên sau vài tầng của hierarchy thì các nhà thống kê Bayes cũng sẽ&nbsp; mệt và dửng lại. Trên thực tế, khi đó vai trò của các tham số tầng rất cao không còn ý nhiều trong chuyện chi phối các biểu hiện của mô hình nữa). Việc định ra cách tham số hóa các tham số còn gọi là sự định ra các prior distribution **_(phân bố tiên nghiệm_**) cho các tham số ngẫu nhiên. Áp dụng  _**công thức ****Bayes**_ (Bayes rule) thì tính được posterior distribution, dịch là _**phân bố hậu nghiệm**_. Conjugate prior thì gọi là _**phân bố tiên nghiệm liên hợp**_. Tham số hóa cho các tham số hyper còn gọi là sự định ra các hyperprior (_**phân bố tiên nghiệm thượng tầng**_). Quyết định lựa chọn prior nào (**_sự chỉ định tiên nghiệm_**) phụ thuộc vào sự giằng co giữa tiên nghiệm (prior knowledge), thực nghiệm từ dữ liệu (empirical data), và sự thuận tiện về tính toán (computational convenience). Sử dụng các phân bố tiên nghiệm liên hợp (phát âm đầy mồm!) là một ví dụ của sự thuận tiện. Sự giẳng co giữa tiên nghiệm và thực nghiệm chẳng qua là một thể hiện của dao cạo Occam, dưới nhãn quan của trường phái Bayes.

Dân tần suất thì không thích khái niệm tham số hyper chút nào, mà cho rằng các tham số phải là không ngẫu nhiên. Về mặt mô hình mà nói thì cách nhìn này là cái trói vô hình, theo quan điểm Bayes những tham số kiểu này là vẫn có thể coi là ngẫu nhiên theo _một độ đo Dirac_ (_**độ đo nguyên tử **_– atomic measure), một sự ràng buộc rất chặt không cần thiết. Cho nên, trong lịch sử mô hình của các nhà tần suất thường không giàu có bằng mô hình của các nhà Bayes. Tuy không nhất thiết phải là như vậy.

## **2.6 Dao cạo của Occam.** Như ông Gớt nói là mọi chân lý đều màu xám, còn cây đời thì mãi mãi xanh tươi. Thay chữ chân lý bằng chữ mô hình, thay chữ cây đời bằng chữ dữ liệu quan sát được, ta có một biên phản cho các nhà thống kê. Bác George Box có một câu nổi tiếng tương tự — mọi mô hình đều sai, chỉ có những mô hình hữu ích hay không. Cho nên ta phải nhìn nhận các mô hình là cách chúng ta _**xấp xỉ **_thế giới thực nghiệm. Vì vậy ngoài _**sai số ước lượng**_ (estimation error) của các tham số, còn có một dạng sai số gọi là _**sai số xấp xỉ **_(approximation error). Mô hình dùng ngôn ngữ thống kê và các cấu trúc toán học (như các quá trình stochastic) làm viên gạch, nhưng lại được ước lượng, điều chỉnh (update), và đánh giá, phân tích bằng dữ liệu thật.&nbsp; Công cụ toán học càng mạnh thì_** tính phức tạp mô hình**_ (model complexity) càng lớn, dẫn đến khả năng biểu diễn của một mô hình càng lớn, khi đó sai số xấp xỉ sẽ nhỏ, song việc ước lượng (estimation) từ dữ liệu cũng có thể lớn lên.&nbsp; Đây chính là _**giằng co**_ (tradeoff ) giữa sai số xấp xỉ và sai số ước lượng. Hiện tượng này gọi là cái **_dao cạo của Occam_** (Occam’s razor),&nbsp; luôn luôn ám ảnh và xuyên suốt mọi quyết định trong việc thiết kế và đánh giá một mô hình học. Sợ nhất là mô hình overfit dữ liệu (**_quá rộng_**) Một đánh giá khách quan đối với sự hiệu quả và tích hữu ích của một mô hình là tính dự báo của nó, và nói chung thì lỗi dự báo thường được chặn bởi hai dạng sai số nói trên. Liên quan đến các khái niệm xấp xỉ: Model misspecification gọi là sự _**chỉ định mô hình không chuẩn**_. Khái niệm model identifiability gọi là _**tính khả nhận diện mô hình**_. Parameter identifiability là **_tính khả nhận diện của tham số_**.

Tóm tắt: joint probability, marginal probability, conditional probability, model identifiability, model mis-specification, model choice, model selection, parameter identifiability, consistency, parametric model, nonparametric, exponential family, curved exponential family, graphical model, hierarchical model, mixture model, hidden markov model, copula model, latent/hidden variables, nonparametric Bayesian model, density, intensity measure, analysis of variance, functional data, curve data, prior distribution, posterior distribution, a priori, a posteriori, sufficient statistics, order statistics, mean parameterization, canonical parameterization, normalizing constant, log-partition function, mean function, covariance function, covariates, features, conjugate prior, conjugacy

# **3. Các phương pháp suy diễn thống kê **

## **3.1 Tổng quan. **Cần phân biệt _**suy diễn thống kê**_ (statistical inference) với **_suy diễn xác suất_** (probabilistic inference). Cái sau chỉ là sự tính toán các xác suất điều kiện trên cơ sở mô hình xác suất. Còn SDTK là suy diễn trên cơ sở mô hình thống kê với sự hiện diện của số liệu. Có hai vấn đề chính, một là **_suy diễn về tham số_**, hay còn gọi là **_ước lượng về tham số_** (parameter estimation), và **_dự báo_** (prediction). Với nhãn quan Bayes thì suy diễn thống kê còn gọi là _**suy diễn Bayes**_, về mặt toán học thì không khác gì suy diễn xác suất vì cả tham số và dữ liệu đều được mô tả bằng biến ngẫu nhiên. Cho nên về mặt khái niệm thì đơn giản, mẫu mực. Với nhãn quan tấn suất thì cách tiếp cận đến các vấn đề suy diễn thống kê khó khăn hơn về mặt khái niệm, và đòi hỏi các cách tiếp cận không mẫu mực. Trong học máy thì vấn đề ước lượng về tham số còn gọi là **_học. _**

Nếu như trong vấn đề xác định mô hình thì quan điểm Bayes và quan điểm tần suất có tính tương hỗ nhau (ví dụ, anh Bây nói với với anh Tần: Tôi mệt rồi, cho phép cái tham số hyper của tôi là không ngẫu nhiên nhá — và anh Tần nói với anh Bây: Cho tôi gọi tham số của anh là biến ẩn nhá), thì trong vấn đề suy diễn, hai quan điểm này xung khắc nhau quyết liệt bất phân thắng bại. Quan điểm của Bây là: đối với vấn đề ước lượng tham số thì chỉ suy diễn điều kiện vào dữ liệu có sẵn (conditioning on data), và “**_marginalize out/ integrate out_**” (?) các tham số ngẫu nhiên trong việc dự báo. Quan điểm của Tần là: đồi với vấn đề ước lượng tham số thì phải suy diễn cho cả _**dữ liệu tưởng tượng**_ (imaginary data, và dùng ước lượng “**_plug-in_**” (?) trong việc dự báo. Tiêu chuẩn của Bây là lạc quan, quan tâm nhiều đến **_phân tích trường hợp trung bình_** (average-case analysis). Tiêu chuẩn của Tần rất bi quan, chú trọng nhiều hơn đến _**phân tích tình huống xấu nhất**_ (worst-case analysis). Đây chỉ là hai thái cực để cho thấy sự khác biệt. Trên thực tế có thể&nbsp; kết hợp cả hai cách tiếp cận trong việc suy diễn từ dữ liệu.

Có một số vấn đề suy diễn cụ thể hơn, và do đó có một số lexicon riêng: Point estimation gọi là_** ước lượng điểm**_ (một khái niệm của TK Tần). Hypothesis testing gọi là **_kiểm định lý thuyết _**(phép thử lý thuyết?).&nbsp; Classification gọi là **_vấn đề phân lớp_**. Clustering gọi là **_vấn đề chia nhóm_**. Bài toán ranking trong học máy gọi là **_vấn đề phân hạng_**.&nbsp; _**Supervised learning**_ gọi là **_học có nhãn, học có hướng dẫn_**. Unsupervised learning gọi là _**học không nhãn (học không có hướng dẫn, học không thầy)**_. Sequential analysis gọi là **_phân tích chuỗi/ phân tích tuần tự_** (?), mà cụ thể có bài toán optimal stopping dịch là bài toán _**dừng tối ưu**_. Survival analysis gọi là **_phân tích sự sống sót_** (?). Vấn đề change point detection gọi là bài toán _**phát hiện điểm thay đổi**_. Chú ý là tất cả các vẫn đề suy diễn cụ thể này đều có thể hiểu tổng quát theo một trong hai vấn đề suy diễn (ước lượng tham số, hoặc dự báo), đều có thể tiếp cận theo cách nhìn Tần hay Bây, nhưng có thể sự điểu chỉnh một chút về cách đánh giá của suy diễn.

## **3.2 Lý thuyết quyết định**. Nền tảng lý thuyết của suy diễn thống kê chính là _**lý thuyết quyết định**_ của Abraham Wald. Cần khái niệm rủi ro (risk). Rủi ro Bayes là Bayes risk. Rủi ro là kỳ vọng của _**hàm thiệt hại/tổn thất/thiệt/mất **_(loss function). Dân kinh tế sẽ dùng hàm utility (**_hàm tiện ích__/thỏa dụng_**) thay vì dùng hàm thiệt hại. Một khái niệm tương tự là hàm reward (?)&nbsp; trong môn học reinforcement learning(?), và quá trình quyết định Markov.

Lý thuyết quyết định là cái ô chung cho cả hai trường phái Bây và Tần, nhưng với dân Tần thì có nhiều việc phải lo hơn. _**Estimator**_ dịch là _**cách ước lượng**_ cho một tham số, và là một hàm số áp dụng vào dữ liệu. Như vậy cũng giống một thống kê, như vậy có thể coi một thống kê là một cách ước lượng thô sơ.&nbsp; Estimate là _**một ước lượng**_ cụ thể cho một tham số nào đó. Trong bài toán phân lớp thì estimator còn gọi là một learning machine (_**máy học**_), estimate sẽ là _**hàm số phân lớp**_ (classifier).&nbsp; Trong vấn đề kiểm định lý thuyết (hypothesis testing) thì cái phải ước lượng là một_** hàm số quyết định**_ (decision function).&nbsp; Dù theo nhãn quan nào thì đều cần tìm ước lượng theo tiêu chuẩn có _**giá trị rủi ro tối thiểu**_ (minimum risk criterion).&nbsp; Nhưng rủi ro của anh Bây thì khác với anh Tần.&nbsp; _**Kỳ vọng tần suất**_ (frequentist expectation) là kỳ vọng của hàm mất đối với phân bố của dữ liệu (ảo tưởng) trên cơ sở một mô hình với một tham số có sẵn. _**Kỳ vọng Bayes**_ là giá trị kỳ vọng của hàm mất đối với phân bố điều kiện của tham số trên cơ sở dữ liệu có sẵn. Nói cách khác, với anh Tần thì dữ liệu là ngẫu nhiên, với anh Bây thì tham số là ngẫu nhiên. Nếu lấy kỳ vọng của kỳ vọng tần suất đối với phân bố của tham số, hoặc lấy kỳ vọng của kỳ vọng Bayes đối với phân bố của dữ liệu thì ta cùng nhận được Rủi ro Bayes!

Một số hàm thiệt hại thông dụng: **_Hàm thiệt&nbsp; 0-1_**. Khi đó Rủi ro Bayes gọi là _**Lỗi Bayes **_(Bayes error).&nbsp; _**Hàm thiệt bình phương**_ (square loss). _**Hàm thiệt mũ**_ (exponential loss). **Hàm thiệt logit** (logistic loss). Surrogate loss sẽ được dịch là _**hàm thiệt thế chỗ**_ (?). Để so sánh các cách ước lượng (estimator) khác nhau người ta có thể dùng tiêu chuẩn Bayes (thông qua việc so sánh _**Rủi ro Bayes**_). Dân tần suất sẽ hay dùng **_tiêu chuẩn minimax_**, mượn từ lý thuyết trò chơi (mà cuộc chơi ở đây là giữa nhà thống kê và Trời — chỉ Ông Trời biết chân lý (mô hình đúng là gì, và ông trời mỗi lần ra tay sẽ nhả ra một mẫu dữ liệu). Cần một số phẩm chất cho các cách ước lượng, như khái niệm unbiasedness (?), admissibility (?), consistency (**_nhất quán_**), invariance (_**bất biến phương sai**_), efficiency (**_hiệu quả_**), superefficiency (**_siêu hiệu quả_**). Dân Bayes chủ quan không quan tâm đến mấy cái chuẩn này, vì họ đã có niềm tin son sắt vào tiên nghiệm rồi, và suy diễn Bayes bằng cách tính phân bố hậu nghiệm là xong. Tuy vậy phương pháp suy diễn Bayes chủ quan có nhiều tính chất lý thuyết rất tốt. Suy diễn dựa trên cơ sở của phân bố hậu nghiệm được chứng minh là tối ưu theo tiêu chuẩn Rủi ro Bayes. Dân Bayes khách quan thì không quá tự tin như dân Bayes chủ quan, nên họ muốn phân bố tiên nghiệm phải có những phẩm chất tốt. _**Tính nhất quán hậu nghiệm**_ (posterior consistency) là một phẩm chất quan trọng.

## **3.3 Các cách ước lượng/học thống kê.** Tôi đặt vài viên gạch ở đây. Khi nào rỗi sẽ viết dần dần. Bạn nào có nhã hứng đóng góp từng paragraph vào các mục sau (hoặc các mục chưa ghi) xin cho biết. Ước lượng hay học ở đây vẫn trên cơ sở một họ mô hình định sẵn. Còn vấn đề khó hơn là chọn mô hình (model selection), so sánh các mô hình, đặc biệt giữa các mô hình có độ phức tạp khác hẳn nhau. Kiểm định giả thuyết&nbsp; là một dạng rất đặc biệt của lựa chọn giữa các mô hình, song vẫn có thể hiểu gọn trong phạm vi ước lượng.

**Empirical risk minimization**. Rủi ro được định nghĩa trên cơ sở hàm phân bố của mô hình (chân lý — chỉ có Trời mới biết). Chỉ có thể tiếp cận đến mô hình này thông qua _**quá trình thực nghiệm **_(empirical process). Nói cách khác, rủi ro phải được ước lượng bẳng **_rủi ro thực nghiệm_** (empirical risk). Hầu hết các cách ước lượng của phe Tần suất đều ở dạng tính rủi ro thực nghiệm cực tiểu (empirical risk minimization (ERM)). Một lexicon đồng nghĩa là _**M-estimation**_ (ước lượng M), M có nghĩa là maximization hoặc minimization. Cách _**ước lượng dựa vào moment **_(moment-based estimation/ moment matching) thực ra cũng có thể được động viên và liên hệ với cách ước lượng rủi ro thực nghiệm cực đại. Một vấn đề đau đầu cho cách ước lượng rủi ro cực tiểu là phải chọn hàm mất gì? Có một số tên riêng: Nếu hàm mất là hàm bình phương, thì ta có phương pháp **_bình phương cực tiểu_** (least square) rất thông dụng trong hồi quy.

**Maximum likelihood và nguyên tắc likelihood**. Nếu mô hình thống kê chỉ định ra một hàm phân bố cho dữ liệu, thì ta có khái niệm _**likelihood (khả năng?**_). Đây là hàm số của tham số, nhưng được lại là ngẫu nhiên vì được định nghĩa trên cơ sở dữ liệu ngẫu nhiên. Likelihood chính là một ví dụ tiêu biểu (nhất) của rủi ro thực nghiệm. Hàm mất tương ứng ở đây là hàm logarithm của mật độ. Maximum likelihood dịch là cách **_ước lượng khả năng cực đại_** (?), một phát kiến vĩ đại của Ronald Fisher. Đây là cách ước lượng thông dụng, đa năng bậc nhất trong ngành thống kê (ít nhất là với nhãn quan tần suất). Với các mô hình tham số thì cách ước lượng này được đảm bảo bởi tính nhất quán (consistency) — mô hình sẽ được ước lượng chính xác nếu số dữ liệu tiến đến vô hạn. Tại sao hàm mất lại là hàm logarithm của mật độ mà không phải là một hàm số nào khác? Đây là một ví dụ của sự diệu kỳ bất ngờ của toán học — câu trả lởi truy ra khái niệm độc lập, khái niệm tập trung của độ đo trong xác suất, và tính lồi trong giải tích (và hình học). **_Nguyên tắc khả năng_** (likelihood principle) cho rẳng hàm khả năng là một thống kê đầy đủ (sufficient statistics). Nguyên tắc này phá sản trong ngữ cảnh phi tham số.

**Regularization/Penalization/Shrinkage. **Với sự ước lượng các mô hình phi tham số thì chỉ dựa vào dữ liệu (thông qua hàm khả năng (likelihood) hoặc tổng quát hơn, hàm rủi ro thực nghiệm) không đủ. Cần phải có sự điều chỉnh trong việc lấy cực đại/cực tiểu thông qua khái niệm regularization (**_kiểm soát_**), còn gọi là penalization (_**soát phạt)**_. Regularized empirical risk gọi là _**rủi ro thực nghiệm có kiểm soát**_.&nbsp; Khái niệm kiểm soát, soát phạt bắt nguổn từ một phát hiện bất ngờ của Charles Stein về shrinkage estimator (**_cách ước lượng co_**). Cho nên nhiều khi người ta cũng gọi nhóm ước lượng này là ước lượng co.&nbsp; Để dùng một số lượng dữ liệu hữu hạn mà ước lượng các đại lượng (tham số) vô hạn hoặc có số chiều đủ lớn (cho dù số dữ liệu có lớn đến đâu và tiến dần đến vô hạn đi chăng nữa) thì vẫn phải có sự kiểm soát trong ước lượng, và không thể dựa hoàn toàn vào dữ liệu thực nghiệm được.&nbsp; Theo nhãn quan Bayes thì điều này chính là sự giằng co giữa thực nghiệm và tiên nghiệm. Co (shrinkage) ở đây chính là co về tiên nghiệm.

**Phương pháp phân tích hậu nghiệm/ học Bayes. **Phương pháp phân tích hậu nghiệm (a posteriori analysis), cụ thể là cách**_ suy diễn hậu nghiệm_** (posterior inference), **_suy diễn Bayes_** (Bayesian inference),_** học Bayes**_ (Bayesian learning),… đều mô tả cùng một cách ước lượng theo trường phái Bayes. Đó là thay vì người ta ước lượng tham số (không ngẫu nhiên) như trong trường phái tần suất, người ta sẽ tính hàm phân bố hậu nghiệm cho tham số thông qua công thức Bayes. Cách này mẫu mực — phần việc chính ở đây là chỉ định ra phân bố tiên nghiệm ra sao, và tính toán phân bố hậu nghiệm thế nào (vì phải tính tích phân rất phức tạp về mặt tính toán).&nbsp; Chú ý rằng cách ước lượng maximum likelihood chẳng qua là tính **_mốt_** (mode) của phân bố hậu nghiệm, nếu phân bố tiên nghiệm được chọn là **_phân bố đề_**u (uniform distribution). Trong phân tích Bayes, đặc biệt là với mô hình tham số, thì không phải lo lắng gì về việc kiểm soát (regularization). Nhưng nếu phân bố tiên nghiệm là một quá trình ngẫu nhiên (trong mô hình phi tham số) thì vẫn phải lo lắng về chuyện kiểm soát tính phức tạp của tiên nghiệm (complexity of prior distribution). Một công cụ là sensitivity analysis (**_phân tích tính nhạy cảm_**) của phân bố cho tham số.

**Phương pháp Bayes thực nghiệm (empirical Bayes). **Phương pháp này có thể xem cách ước lượng tần suất cho mô hình đa tầng. Mô hình đa tầng là một công cụ lý tưởng trong việc kiểm soát độ phức tạp của các mô hình cho tham số.

## **3.4. Các vấn để suy diễn cụ thể hơn**.

Hypothesis testing. Trong kiểm định giả thuyết có một số khái niệm quan trọng: Null hypothesis gọi là ? Alternative hypothesis? Có hai loại lỗi: Lỗi loại một (type-1 error) và lỗi loại hai (type-2 error). Còn gọi là tỷ lệ lỗi dương tính (false positive) và lỗi âm tính (false negative) trong đánh giá các treatment (?) trong y học. Trong công nghệ thì type-1 error gọi là false alarm error rate (?), type-2 error chính là misdetection error rate (?). Tất cả các loại rỗi này đều là hàm rủi ro đối với hàm thiệt 0-1. Cách ước lượng trong kiểm định giả thuyết gọi là một hàm quyết định. Và người ta sử dụng hàm quyết định thực hiện phép thử (test) cho giả thuyết. Một phép thử được đánh giá thông qua các bảo đạm về giới hạn của các lỗi kể trên. Sự giẳng co giữa lỗi loại một và loại hai được biểu diễn bẳng ROC curve (_**đường cong ROC**_). Các khái niệm liên hệ còn có significance (?). Confidence interval dịch là ? p-value dịch là giá trị p. Power của phép thử gọi là _**sức mạnh**_.&nbsp; Nếu chỉ có hai giả thuyết đẻ so sánh thì hàm quyết định tối ưu chính phải dựa vào likelihood ratio (_**phân số khả năng**_). Likelihood ratio test gọi là phép thử dựa vào phân số khả năng. Công cụ để đánh giá sức mạnh của một phép thử là thống kê giới hạn (asymptotic statistics).

Kiểm định giả thuyết xuất phát từ thống kê tấn suất, do công của Neyman và Pearson. Khái niệm này rất phản trực quan, và phải đợi đến Wald mới thống nhất cách suy diễn này với cách hình thức suy diễn kiểu khác trong thống kê.&nbsp; Nếu tiếp cận theo nhãn quan Bayes thì KDGT khá là đơn giản, không khác gì việc ước lượng một mô hình là bao. Cần khái niệm phân bố tiên nghiệm cho các giả thuyết. Khái niệm Bayes factor sẽ được dịch là ?

Sequential analysis. Trong phân tích tuần tự (sequential analysis) thì có sự giẳng co của lỗi Bayes và thời gian trễ (delay time) của quyết định về giả thuyết. Khái niệm thử thông dụng là sequential likelihood ratio test (**_phép thử dựa theo chuỗi phân số khả năng_**). Công cụ lý thuyết đẻ đánh giá sức mạnh của phép thử là các phân tích về thời gian dừng, phân tích các loại thời điểm vượt biên, v.v. trong lý thuyết xác suất về quá trình Markov.

Classification/regression/ranking. Trong bài toán phân lớp thì người ta gọi một cách ước lượng để phân lớp là một _**máy họ**_c (learning machine). Tham số cần ước lượng ở đây gọi là một _**hàm phân loại**_ (classifier). Có thể tiếp cận vấn đề này trên cơ sở mô hình tham số hoặc mô hình phi tham số. Để học được máy (mô hình) thường đòi hỏi nhiều tính toán,&nbsp; chứ không phải các thống kê đơn giản như trong kiểm định giả thuyết cổ điển. Cho nên dẫn đến những quan tâm về vấn đề hiệu quả của các giải thuật học/ ước lượng.&nbsp; Cách học/ ước lượng, về mặt tính toán, có lexicon riêng là training (**_việc huấn luyện_**).&nbsp; Dữ liệu cần cho việc huấn luyện gọi là**_ dữ liệu huấn luyện_** (training data). **_Phép thử_** một hàm phân loại với dữ liệu mới gọi là testing. **_Dữ liệu thử_** chính là test data. Nếu có hai lớp để phân loại thì hàm phân loại tối ưu phải dựa vào likelihood ratio, rất giống như trong kiểm định giả thuyết. Một khác biệt căn bản giữa bài toán phân lớp với bài toán kiểm định lý thuyết là chỗ này: Cái đầu phải thử giả thuyết cho từng mẫu một. Cái sau chỉ phải thử giả thuyết một lần cho cả đám đông. Có rất nhiều phương pháp phân lớp, với các mô hình tham số và phi tham số, và các giải thuật học/ước lượng rất phong phú. Kinh điển thì có linear discriminant analysis (**_phân tích phân biệt tuyến tính_**), logistic regression (_**hồi quy logit)**_. Hiện đại hơn thì có _**mạng nơ ron**_ (neural network), radiant basis network (?), support vector machines (?),…

**_Bài toán hồi quy_** (regression analysis) tương tự như bài toán phân lớp, khác ở đây là cần phải ước lượng/học phương trình hồi quy (thay vì hàm phân loại). Hàm phân lớp chỉ có giá trị rởi rạc, còn phương trình hồi quy thường tính ra các giá trị liên tục. Bài toán phân cấp gần giống bài toán phân cấp ở chỗ hàm phân loại cũng có giá trị rời rạc (và không phải nhị phân), nhưng dữ liệu huấn luyện các mẫu về sự so sánh giữa các cấp chứ không phải nhãn lớp (cấp).

Dimensionality reduction/ exploratory data analysis. _**Phân tích khám phá**_ với dữ liệu là một mảng quan trọng. Principle component analysis dịch là **_phân tích thành phần chủ yếu_**. Multidimensional scaling dịch là ?. Independence component analysis gọi là **_phân tích thành phần độc lập_**. Vấn đề chia nhóm (clustering) cũng có thể đặt vào đây, nhưng các phương pháp chia nhóm dựa vào mô hình (model-based clustering) đã phát triển đến mức độ rất tinh xảo, và nên đặt nó vào nhóm suy diễn dựa vào mô hình.

## **3.5 Thống kê&nbsp; ở vô hạn, lý thuyết học, và lý thuyết thông tin (asymptotic statistics, learning theory, information theory)**

Thống kê ở asymptotic chính là cơ sở lý thuyết giả thích sự hiệu quả và giới hạn của các suy diễn thống kê.&nbsp; Thống kê ở vô hạn nghiên cứu tính chất của các phép ước lượng khi lượng mẫu (sample size) tiến đến vô hạn. Một vấn đề người ta cần quan tâm là các tiêu chuẩn dựa vào rủi ro phải tiến về 0. Tính chất này gọi là_** tính nhất quán**_ (consistency) của một cách ước lượng. Nếu đã nhất quán rồi thì còn quan tâm rate of convergence –_** tốc độ hội tụ **_– của các rủi ro. Ngoải ra ta còn quan tâm đến tính chất về phân bố của sự hội tụ. Một tính chất quan trọng thường gặp là asymptotic normality (**_sự bình thường ở giới hạn_**). Với trường phái Bayes khách quan thì có khái niệm _**nhất quán hậu nghiệm**_ (posterior consistency) — khi số mẫu tiến đến giới hạn thì phân bố hậu nghiện phải tập trung về một điểm, điểm đó chính là giá trị chân lý của tham số cần ước lượng. Tính chất này mang tính tấn suất, vì nó vẫn giả sử tham số là không ngẫu nhiên, mặc dù ta có thể định ra phân bố tiên nghiệm và làm phân tích hậu nghiệm. (Các nhà Bayes chủ quan cuồng tín sẽ ngoảnh mặt quay gót khi ai nó nói đến khái niệm này).

Một vấn đề khác người ta cũng quan tâm là tính chất về phân bố của các thống kê được sử dụng trong các phép suy diễn cụ thể, như trong kiểm định giả thuyết chẳng hạn. Nhờ tính chất phân bố của thống kê (ở điều kiện mẫu vô hạn) mà ta có thể có những đảm bảo nhất định về các rủi ro của suy diễn.

Công cụ toán học của phân tích thống kê asymptotic là tính chất**_ tập trung của độ đo_** (concentration of measure), đặc biệt trong ngữ cảnh của _**quá trình thực nghiệm**_ (empirical process). Empirical process theory là tên thường gọi. Công cụ quan trọng có symmetrization argument (**_mẹo cân đối hóa_**). Chaining method dịch là **_phương pháp chuỗ_**i, một phương pháp mẫu mực để chứng minh các chặn trên cho tiếm hàm rủi ro (định nghĩa trên quá trình thực nghiệm) bởi các đại lượng mô tả **_sự phức tạp của mô hình_** (model complexity). Khái niệm sự phức tạp của mô hình đến từ **_lý thuyết xấp xỉ_** (approximation theory).&nbsp; Các khái niệm chính gồm có covering number (**_số đĩa phủ_**), packing number (**_số đĩa chèn_**?). Khái niệm entropy (Kolmogorov entropy chứ không phải Shannon entropy) được giữ nguyên trong lexicon. Ngoài các chặn trên, còn có thể chứng minh các chặn dưới, gọi chung là _**chặn minimax**_. Chặn này cho biết tốc độ hội tụ của rủi ro tốt nhất có thể được (trong mọi cách ước lượng) đối với một lớp mô hình cho sẵn. Đối với lớp mô hình tuyến tính thì độ phức tạp của mô hình có thể mô ta bằng một khái niệm tổ hợp nổi tiếng trong lý thuyết học (learning theory) của Vapnik và Chervonenkis,&nbsp; _**số chiều VC **_(VC dimension).

Lý thuyết thông tin (information theory) của Shannon chính là lý thuyết thống kê giới hạn cho một số bài toán suy diễn cụ thể trong công nghệ thông tin, công nghệ nén và truyền tải dữ liệu. LTTT cũng tập trung nhiều vào đại lượng có thể dùng để mô ta sự hiệu quả của một giải thuật suy diễn. Các đại lượng này xuất hiện trên exponent của các chặn trên và chặn dưới của các rủi ro của suy diễn, không chỉ trong các bài toán cụ thể trong công nghệ thông tin, mà còn trong các ngữ cảnh suy diễn thống kê tổng quát. Các khái niệm quan trọng gồm có: Shannon entropy, conditional entropy (**_entropy điều kiện_**), Kullback-Leibler divergence (**_độ phân kỳ Kullback-Leibler_**), mutual information (**_thông tin chung)_**. Do đó, các khái niệm về thông tin này còn có vai trò quan trọng trong các vấn đề về sự lựa chọn mô hình (model selection), thiết kế thí nghiệm (experimental design) và trong các phân tích khám phá. Về mặt toán học, các khái niệm thông tin này đều là các phiếm hàm mô tả sự ngẫu nhiên và quan hệ của một hay nhiều hàm phân bố xác suất. Các khái niệm liên hệ có thể kể đến: Fisher information (**_thông tin Fisher_**), phương sai.

## **3.5 Lựa chọn mô hình (model selection).**

## **3.6 Thiết kế thí nghiệm (experiment design). _Tôi không biết đủ sâu/rộng để viết về phần này. Hy vọng bác nào là chuyên gia xắn tay vào viết giúp một vài paragraph.

Tóm tắt: Bayesian learning, Bayesian inference, posterior inference, maximum likelihood, posterior consistency, asymptotic consistency, asymptotic normality, sensitivity analysis, stability analysis, heat map,&nbsp; efficiency, superefficiency, estimator, estimate, learning algorithm, learner, chaining method, symmetrization, covering number, free probability

ROC, hypothesis test, Bayes error, approximation error, estimation error, null hypothesis, alternative hypothesis, type-1 error, type-2 error, power, significance, p-value, Bayesfactor, nested design, empirical Bayes method, shrinkage, sequential analysis, sequential change point analysis, online analysis, distributed algorithm

# **4. Các giải thuật thống kê, học giả**

## **_4.1 Tổng quan._** Thống kê cổ điển không có khái niệm về giải thuật. Khi chưa có công cụ máy tính người ta chỉ có thể nghiên cứu tính chất và áp dụng các cách ước lượng khá giản đơn về mặt tính toán. Sự ra đời của máy tính và thông qua đó phát triển của lĩnh vực giải thuật và học máy thổi một làn gió mới vào vấn đề suy diễn từ dữ liệu. Làn gió này bắt đầu rất nhỏ từ thập niên 60, mạnh dần lên vào thập niên 80, đến thập niên 90 và những năm đầu thế kỷ này có lẽ nó đã trở thành bão. Cơn bão của khoa học tính toán đang làm thay đổi hoàn toàn khung cảnh của thống kê hiện đại, hứa hẹn những bước phát triến ngoạn mục trong tương lai. Về mặt lý thuyết, trước kia, ta chỉ quan tâm quan hệ giữa lượng mẫu và độ hiệu quả của suy diễn thống kê thông qua sự chính xác của các phép ước lượng.&nbsp; Nay, ta còn phải quan tâm đến hai đại lượng mới: đó là _**sự phức tạp về tính toán**_ — computational complexity (về mặt thời gian và bộ nhớ), và **s**_**ự xấp xỉ của mô hình**_ (approximation error) , vì bây giờ chúng ta đã có thể phát triến và nghiên cứu các dạng mô hình mạnh hơn trước, các phép ước lượng phức tạp hơn trước. Đại lượng đầu tiên, sự phức tạp về tính toán, đến từ khoa học máy tính. Đại lượng thứ hai, tính xấp xỉ của mô hình, đến từ thuyết xấp xỉ của toán ứng dụng, và lý thuyết xác suất. Một sự thay đổi rõ nét nhất trong sự phát triển của các phương pháp suy diễn thống kê hiện đại chính là sự lên ngôi của trường phái Bayes, vì các công cụ giải thuật ngày nay cho phép thực hiện phân tích Bayes một các hiệu quả hơn về mặt tính toán. Các mô hình Bayes còn nối lại quan hệ mật thiết giữa những người xây dựng mô hình thống kê với những người nghiên cứu về quá trình ngẫu nhiên trong lý thuyết xác suất.&nbsp; Với sự hiện diện của khái niệm phức tạp tính toán và khái niệm xấp xỉ trong suy diễn thống kê, sự đối nghịch giữa hai trường phái Bayes và Tần suất bị loãng đi và mất dần tính cực đoan cuồng tín của thế kỷ 20. Người ta bắt đầu có cái nhìn cân bằng hơn về vai trò và quan hệ giữa hai trường phái này.

expectation-maximization algorithm, variational inference, message-passing algorithm, belief propagation, back propagation, training, testing, classification, clustering, hierarchical clustering, linear regression, kernel method, sparsity

, regularization, penalization, cross-validation, leave-one-out, boosting, bagging, bootstrap, compressed sensing, quantization, heteroscedasticity, multi-modality,

# **5. Các phương pháp tối ưu trong suy diễn thống kê**

simulated annealing, local search, global search, heuristic search, restart, hill-climbing, saddle point, sampling, importance sampling, proposal distribution, acceptance probability, heat bath method, particle filtering, filtering, smoothing
